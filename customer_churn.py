# -*- coding: utf-8 -*-
"""Customer Churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RtwUIWNIStCNucJY_Z_y-iho67_zKeDh

# Customer Churn Prediction
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import sklearn
import numpy as np
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt

# %matplotlib inline

"""# Loading Data"""

df = pd.read_excel('customer_churn_large_dataset.xlsx')
df.shape

"""# Analysing Data"""

df.head()

df.tail()

df.size

df.info()

df.isnull().sum()

df.duplicated().sum()

df.skew(numeric_only = True)

df.corr(numeric_only= True)

df.describe()

df['Churn'].value_counts().plot(kind='barh', figsize=(8, 6))
plt.xlabel("Count", labelpad=14)
plt.ylabel("Target Variable", labelpad=14)
plt.title("Count of TARGET Variable per category", y=1.02);

"""We can see that our data is balance data"""

df['Churn'].value_counts()

# Finding the percentage of churn and not churn
100*df['Churn'].value_counts()/len(df['Churn'])

df.info(verbose = True)

"""# Cleaning and Preparing the Data to use"""

telco_data = df.copy()

telco_data.isnull().sum()

telco_data.columns

# Droping Irrelevent Features
data = telco_data.drop(['CustomerID', 'Name'], axis=1)
data.head()

"""### Encoding Categorical Value to Nemericul"""

data['Location'].unique()

data = pd.get_dummies(data, drop_first=True)
data.head()

"""# Spliting the Data"""

X = data.drop('Churn', axis=1)
y = data['Churn']

X

y

"""### Splinting the data into train and test"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)

"""# Feature Scaling"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

X_train

"""# Model Testing

### Logistic Regression
"""

from sklearn.linear_model import LogisticRegression

log = LogisticRegression()

log.fit(X_train, y_train)

y_pred = log.predict(X_test)

from sklearn.metrics import accuracy_score, precision_score

accuracy_score(y_test, y_pred)

precision_score(y_test, y_pred)

"""### Support Vector Machine"""

from sklearn import svm

svm = svm.SVC()

svm.fit(X_train, y_train)

y_pred2 = svm.predict(X_test)

accuracy_score(y_test, y_pred2)

precision_score(y_test, y_pred2)

"""### KNeighbors Classifier"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()

knn.fit(X_train, y_train)

y_pred3 = knn.predict(X_test)

accuracy_score(y_test, y_pred3)

precision_score(y_test, y_pred3)

"""### Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()

dt.fit(X_train, y_train)

y_pred4 = dt.predict(X_test)

accuracy_score(y_test, y_pred4)

precision_score(y_test, y_pred4)

"""### Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()

rf.fit(X_train, y_train)

y_pred5 = rf.predict(X_test)

accuracy_score(y_test, y_pred5)

precision_score(y_test, y_pred5)

"""### Gradient Boosting Classifier"""

from sklearn.ensemble import GradientBoostingClassifier

from numpy.lib.function_base import gradient

gbc = GradientBoostingClassifier()

gbc.fit(X_train, y_train)

y_pred6 = gbc.predict(X_test)

accuracy_score(y_test, y_pred6)

precision_score(y_test, y_pred6)

final_data = pd.DataFrame({'Model':['LR','SVC','KNN','DT','RF','GBC'],
                           'ACC':[accuracy_score(y_test, y_pred),
                                  accuracy_score(y_test, y_pred2),
                                  accuracy_score(y_test, y_pred3),
                                  accuracy_score(y_test, y_pred4),
                                  accuracy_score(y_test, y_pred5),
                                  accuracy_score(y_test, y_pred6),
                                  ],
                           'PS':[precision_score(y_test, y_pred),
                                 precision_score(y_test, y_pred2),
                                 precision_score(y_test, y_pred3),
                                 precision_score(y_test, y_pred4),
                                 precision_score(y_test, y_pred5),
                                 precision_score(y_test, y_pred6),
                                 ]
                           })

final_data

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming final_data is your DataFrame

sns.barplot(x='Model', y='ACC', data=final_data)
plt.xticks(rotation=90)
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Accuracy of Different Models')
plt.tight_layout()
plt.show()

"""# Tunning the Model"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV

# Define the parameter grid to search
param_grid = {
    'fit_intercept': [True, False]
}

# Create a LinearRegression model
model = LinearRegression()

# Create GridSearchCV object
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')

# Fit the grid search to the training data
grid_search.fit(X_train, y_train)

# Print the best parameters and best score
print("Best Parameters:", grid_search.best_params_)
print("Best Negative Mean Squared Error:", grid_search.best_score_)

# Evaluate the best model on the test data
best_model = grid_search.best_estimator_
test_predictions = best_model.predict(X_test)

# You can now analyze the test predictions further or calculate performance metrics

grid_search.cv_results_

gs_df = pd.DataFrame(grid_search.cv_results_)
gs_df

# Use the best parameters from GridSearchCV
best_params = grid_search.best_params_

# Create a LinearRegression model with the best parameters
best_model = LinearRegression(**best_params)

# Fit the model to the training data
best_model.fit(X_train, y_train)

# Predict on the test data
test_predictions = best_model.predict(X_test)

# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)

# Print the evaluation metrics
print("Best Model Accuracy:", accuracy)
print("Best Model Precision:", precision)

"""# Saving The Model"""

import pickle

with open('model_gs', 'wb') as f:
  pickle.dump(grid_search,f)

